{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:04:11.833095Z",
     "start_time": "2018-06-01T09:04:11.827543Z"
    }
   },
   "source": [
    "In this notebook we perform collaborative filtering using gradient descent (without for loops) on the movielens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:23:36.715841Z",
     "start_time": "2018-06-01T09:23:36.576887Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:06:49.171192Z",
     "start_time": "2018-06-01T09:06:49.159868Z"
    }
   },
   "outputs": [],
   "source": [
    "def proc_col(col):\n",
    "    \"\"\"\n",
    "    Function to encode a pandas column with continous ids. \n",
    "    \"\"\"\n",
    "    uniq = col.unique()\n",
    "    name2idx = {o: i for i, o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx[x] for x in col]), len(uniq)\n",
    "\n",
    "\n",
    "def encode_data(df):\n",
    "    \"\"\"\n",
    "    Function to encode rating data with continous user and movie ids using \n",
    "    the helpful fast.ai function from above.\n",
    "    \n",
    "    Arguments:\n",
    "      df: Dataframe with columns user_id,movie_id,rating \n",
    "    \n",
    "    Returns:\n",
    "      df: dataframe with the encode data\n",
    "      num_users\n",
    "      num_movies\n",
    "    \"\"\"\n",
    "    user_encoded, df['userId'], num_users = proc_col(df.userId)\n",
    "    movie_encoded, df['movieId'], num_movies = proc_col(df.movieId)\n",
    "    return df, num_users, num_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering with Gradient Descent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering in matrix factorization form can be represented as $Y = UV^T$ where \n",
    "- Y is the matrix of ratings with rows corresponding to users and columns to movies. This is also known as utility matrix\n",
    "- U is the user embedding matrix with each row capturing one user's features\n",
    "- V is the movie embedding matrix with each row capturing one movies's features\n",
    "\n",
    "An alternate representation would have biases corresponding to movies, users and can be represented as $Y = UV^T + U_0 + V_0^T$ where\n",
    "- $U_0$ is a column vector with user biases\n",
    "- $V_0$ is a column vector with movie biases\n",
    "\n",
    "Each element in the utility matrix (rating of $j^{th}$ movie by $i^{th}$ user) can be computed using the below formula\n",
    "$$\\hat{y}_{ij} = u_{0i} + v_{0j} + u_i \\cdot v_j  $$\n",
    "\n",
    "We will train the embeddings using gradient descent and MSE as loss function. Corresponding gradient descent equations can be written as:\n",
    "\n",
    "$$u_{ik} = u_{ik} + \\frac{2\\eta}{N} \\sum_{j:r_{ij}=1} (y_{ij} - u_{i} . v_{j} - u_{0i} - v_{0j})v_{jk} $$\n",
    "$$v_{jk} = v_{jk} + \\frac{2\\eta}{N} \\sum_{j:r_{ij}=1} (y_{ij} - u_{i} . v_{j} - u_{0i} - v_{0j})u_{ik} $$\n",
    "$$u_{0i} = u_{0i} + \\frac{2\\eta}{N} \\sum_{j:r_{ij}=1} (y_{ij} - u_{i} . v_{j} - u_{0i} - v_{0j})$$\n",
    "$$v_{0j} = v_{0j} + \\frac{2\\eta}{N} \\sum_{j:r_{ij}=1} (y_{ij} - u_{i} . v_{j} - u_{0i} - v_{0j})$$\n",
    "\n",
    "The same equations acan be written in vectorized form as \n",
    "\n",
    "$$\\Delta = (Y - U . V^{T} - U_{0} - V_{0}^{T}) \\otimes R $$\n",
    "\n",
    "Where \n",
    "- $U_{0}$ and $V_{0}$ are bias matrices of order $n_{u} \\times 1$ and $n_{m} \\times 1$ respectively. \n",
    "- R is an $n_{u} \\times n_{m}$ matrix with element $r_{ij}$\n",
    "\n",
    "Numpy broadcasting takes care of the dimension mismatch between $Y$, $U_{0}$ and $V_{0}$\n",
    "\n",
    "$$ U = U + \\frac{2\\eta}{N}\\Delta . V$$\n",
    "$$ V = V + \\frac{2\\eta}{N}\\Delta^{T} . U$$\n",
    "$$ U_{0} = U_{0} + \\frac{2\\eta}{N}\\Delta . I_{v}$$\n",
    "$$ V_{0} = V_{0} + \\frac{2\\eta}{N}\\Delta^{T} . I_{u}$$\n",
    "\n",
    "where $I_{u}$ and $I_{v}$ are unit matrices of shape same as $U_{0}$ and $V_{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:23:20.928401Z",
     "start_time": "2018-06-01T09:23:20.923599Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_embedings(n, K):\n",
    "    \"\"\"\n",
    "    Create a numpy random matrix of shape n, K\n",
    "    \n",
    "    The random matrix should be initialized with uniform values in (0, 6/K)\n",
    "    Arguments:\n",
    "    \n",
    "    Inputs:\n",
    "    n: number of items/users\n",
    "    K: number of factors in the embeding \n",
    "    \n",
    "    Returns:\n",
    "    emb: numpy array of shape (n, num_factors)\n",
    "    \"\"\"\n",
    "    np.random.seed(3)\n",
    "    emb = 6 * np.random.random((n, K)) / K\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:23:55.854028Z",
     "start_time": "2018-06-01T09:23:55.850460Z"
    }
   },
   "source": [
    "### Encoding Ratings as a Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:27:01.950762Z",
     "start_time": "2018-06-01T09:27:01.938887Z"
    }
   },
   "outputs": [],
   "source": [
    "def df2matrix(df, nrows, ncols, column_name=\"rating\"):\n",
    "    \"\"\"\n",
    "    Returns a sparse matrix constructed from a dataframe\n",
    "    \n",
    "    This code assumes the df has columns: MovieID,UserID,Rating\n",
    "    \"\"\"\n",
    "    values = df[column_name].values\n",
    "    ind_movie = df['movieId'].values\n",
    "    ind_user = df['userId'].values\n",
    "    return sparse.csc_matrix(\n",
    "        (values, (ind_user, ind_movie)), shape=(nrows, ncols))\n",
    "\n",
    "\n",
    "def sparse_multiply(df, emb_user, emb_movie):\n",
    "    \"\"\"\n",
    "    This function returns U*V^T element wise multi by R as a sparse matrix.\n",
    "    \n",
    "    It avoids creating the dense matrix U*V^T\n",
    "    \"\"\"\n",
    "    df[\"Prediction\"] = np.sum(\n",
    "        emb_user[df[\"userId\"].values] * emb_movie[df[\"movieId\"].values],\n",
    "        axis=1)\n",
    "    return df2matrix(\n",
    "        df, emb_user.shape[0], emb_movie.shape[0], column_name=\"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:38:17.260108Z",
     "start_time": "2018-06-01T09:38:17.249925Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_new_data(df_val, df_train):\n",
    "    \"\"\"\n",
    "    Encodes df_val with the same encoding as df_train.\n",
    "    \n",
    "    Returns:\n",
    "    df_val: dataframe with the same encoding as df_train\n",
    "    \"\"\"\n",
    "    user_encoded, df_train['userId'], num_users = proc_col(df_train.userId)\n",
    "    movie_encoded, df_train['movieId'], num_movies = proc_col(df_train.movieId)  \n",
    "    \n",
    "    df_val['userId'] = df_val.userId.apply(lambda x: user_encoded.get(x, -1)).astype('int64')\n",
    "    df_val['movieId'] = df_val.movieId.apply(lambda x: movie_encoded.get(x, -1)).astype('int64')\n",
    "    df_val = df_val.drop(df_val[(df_val['userId'] == -1) | (df_val['movieId'] == -1)].index)\n",
    "    \n",
    "    return df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:27:56.348790Z",
     "start_time": "2018-06-01T09:27:56.342330Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost(df, emb_user, emb_movie):\n",
    "    \"\"\"\n",
    "    Computes mean square error\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      \n",
    "    Returns:\n",
    "      error(float): this is the MSE\n",
    "    \"\"\"\n",
    "    ratings = df2matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
    "    predictions = sparse_multiply(df, emb_user, emb_movie)\n",
    "    error = (ratings - predictions).power(2).sum() / ratings.count_nonzero()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:28:32.268881Z",
     "start_time": "2018-06-01T09:28:32.266171Z"
    }
   },
   "source": [
    "### Define Gradient Descent Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:41:41.935685Z",
     "start_time": "2018-06-01T09:41:41.857905Z"
    }
   },
   "outputs": [],
   "source": [
    "def finite_difference(df, emb_user, emb_movie, ind_u=None, ind_m=None, k=None):\n",
    "    \"\"\"\n",
    "    Computes finite difference on MSE(U, V).\n",
    "    \n",
    "    This function is used for testing the gradient function. \n",
    "    \"\"\"\n",
    "    e = 0.000000001\n",
    "    c1 = cost(df, emb_user, emb_movie)\n",
    "    K = emb_user.shape[1]\n",
    "    x = np.zeros_like(emb_user)\n",
    "    y = np.zeros_like(emb_movie)\n",
    "    if ind_u is not None:\n",
    "        x[ind_u][k] = e\n",
    "    else:\n",
    "        y[ind_m][k] = e\n",
    "    c2 = cost(df, emb_user + x, emb_movie + y)\n",
    "    return (c2 - c1) / e\n",
    "\n",
    "\n",
    "def gradient(df, Y, emb_user, emb_movie):\n",
    "    \"\"\"\n",
    "    Computes the gradient.\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      Y: sparse representation of df\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      \n",
    "    Returns:\n",
    "      d_emb_user\n",
    "      d_emb_movie\n",
    "    \"\"\"\n",
    "    N = Y.count_nonzero()\n",
    "    predictions = sparse_multiply(df, emb_user, emb_movie)\n",
    "    delta = Y - predictions\n",
    "    d_emb_user = -(2.0 / N) * delta * emb_movie\n",
    "    d_emb_movie = -(2.0 / N) * delta.T * emb_user\n",
    "    return d_emb_user, d_emb_movie\n",
    "\n",
    "\n",
    "def gradient_descent(df,\n",
    "                     emb_user,\n",
    "                     emb_movie,\n",
    "                     iterations=100,\n",
    "                     learning_rate=0.01,\n",
    "                     df_val=None):\n",
    "    \"\"\"\n",
    "    Computes gradient descent with momentum (0.9) for a number of iterations.\n",
    "    \n",
    "    Prints training cost and validation cost (if df_val is not None) every 100 iterations.\n",
    "    \n",
    "    Returns:\n",
    "    emb_user: the trained user embedding\n",
    "    emb_movie: the trained movie embedding\n",
    "    \"\"\"\n",
    "    Y = df2matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
    "    v_user, v_movie = gradient(df, Y, emb_user, emb_movie)\n",
    "    for i in range(1, iterations + 1):\n",
    "        grad_user, grad_movie = gradient(df, Y, emb_user, emb_movie)\n",
    "        v_user, v_movie = (0.9 * v_user + 0.1 * grad_user), (\n",
    "            0.9 * v_movie + 0.1 * grad_movie)\n",
    "        emb_user -= learning_rate * v_user\n",
    "        emb_movie -= learning_rate * v_movie\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            train_cost = cost(df, emb_user, emb_movie)\n",
    "            print(\"Training Cost: %.4f\" % train_cost)\n",
    "            if df_val is not None:\n",
    "                val_cost = cost(df_val, emb_user, emb_movie)\n",
    "                print(\"Validation Cost: %.4f\" % val_cost)\n",
    "\n",
    "    return emb_user, emb_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Regularized Gradient Descent Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:47:36.303429Z",
     "start_time": "2018-06-01T09:47:36.236715Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_reg(df, emb_user, emb_movie, reg_param):\n",
    "    \"\"\"\n",
    "    Computes mean square error\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      reg_param: regularization parameter\n",
    "      \n",
    "    Returns:\n",
    "      error(float): this is the MSE\n",
    "    \"\"\"\n",
    "    ratings = df2matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
    "    predictions = sparse_multiply(df, emb_user, emb_movie)\n",
    "    mse = (ratings-predictions).power(2).sum() / ratings.count_nonzero() +\\\n",
    "    reg_param * (np.sum(np.square(emb_user)) + np.sum(np.square(emb_movie)))\n",
    "    return mse\n",
    "\n",
    "def gradient_reg(df, Y, emb_user, emb_movie, reg_param):\n",
    "    \"\"\"\n",
    "    Computes the gradient.\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      Y: sparse representation of df\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      reg_param: regularization parameter\n",
    "      \n",
    "    Returns:\n",
    "      d_emb_user\n",
    "      d_emb_movie\n",
    "    \"\"\"\n",
    "    N = Y.count_nonzero()\n",
    "    predictions = sparse_multiply(df, emb_user, emb_movie)\n",
    "    delta = Y - predictions\n",
    "    d_emb_user = -(2.0/N)*delta*emb_movie + 2.0*reg_param*emb_user\n",
    "    d_emb_movie = -(2.0/N)*delta.T*emb_user + 2.0*reg_param*emb_movie\n",
    "    return d_emb_user, d_emb_movie\n",
    "\n",
    "def gradient_descent_reg(df, emb_user, emb_movie, iterations=100, learning_rate=0.01, df_val=None, reg_param=0):\n",
    "    \"\"\"\n",
    "    Computes gradient descent with momentum (0.9) for a number of iterations.\n",
    "    \n",
    "    Prints training cost and validation cost (if df_val is not None) every 100 iterations.\n",
    "    \n",
    "    Returns:\n",
    "    emb_user: the trained user embedding\n",
    "    emb_movie: the trained movie embedding\n",
    "    \"\"\"\n",
    "    Y = df2matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
    "    num_estimates = (emb_user.shape[0] + emb_movie.shape[0]) * emb_user.shape[1]\n",
    "    rp = reg_param/num_estimates\n",
    "    v_user, v_movie = gradient_reg(df, Y, emb_user, emb_movie, rp)\n",
    "    for i in range(0,iterations):\n",
    "        grad_user, grad_movie = gradient_reg(df, Y, emb_user, emb_movie, rp)\n",
    "        v_user, v_movie = (0.9*v_user + 0.1*grad_user), (0.9*v_movie + 0.1*grad_movie)\n",
    "        emb_user -= learning_rate*v_user\n",
    "        emb_movie -= learning_rate*v_movie\n",
    "    \n",
    "        if i%100 == 0:\n",
    "            train_cost = cost_reg(df, emb_user, emb_movie, rp)\n",
    "            print(\"Training Cost: %.4f\" %train_cost)\n",
    "            if df_val is not None:\n",
    "                val_cost = cost_reg(df_val, emb_user, emb_movie, rp)\n",
    "                print(\"Validation Cost: %.4f\" %val_cost)\n",
    "    \n",
    "    return emb_user, emb_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Train-Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:40:18.611096Z",
     "start_time": "2018-06-01T09:40:18.551669Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"ml-latest-small/\"\n",
    "data = pd.read_csv(path + \"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:41:02.035277Z",
     "start_time": "2018-06-01T09:41:01.899804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random split as time based split may lead to cold start problem\n",
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(data)) < 0.8 \n",
    "train = data[msk].copy()\n",
    "val = data[~msk].copy()\n",
    "df_train, num_users, num_movies = encode_data(train.copy())\n",
    "df_val = encode_new_data(val.copy(), train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:42:49.095033Z",
     "start_time": "2018-06-01T09:41:47.818869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cost: 7.2257\n",
      "Validation Cost: 7.3617\n",
      "Training Cost: 4.0767\n",
      "Validation Cost: 4.2013\n",
      "Training Cost: 2.8326\n",
      "Validation Cost: 2.9361\n",
      "Training Cost: 2.1876\n",
      "Validation Cost: 2.2800\n",
      "Training Cost: 1.8059\n",
      "Validation Cost: 1.8946\n",
      "Training Cost: 1.5582\n",
      "Validation Cost: 1.6467\n",
      "Training Cost: 1.3859\n",
      "Validation Cost: 1.4761\n",
      "Training Cost: 1.2600\n",
      "Validation Cost: 1.3528\n",
      "Training Cost: 1.1644\n",
      "Validation Cost: 1.2603\n",
      "Training Cost: 1.0895\n",
      "Validation Cost: 1.1889\n",
      "Training Cost: 1.0293\n",
      "Validation Cost: 1.1324\n",
      "Training Cost: 0.9800\n",
      "Validation Cost: 1.0870\n",
      "Training Cost: 0.9388\n",
      "Validation Cost: 1.0498\n",
      "Training Cost: 0.9038\n",
      "Validation Cost: 1.0190\n",
      "Training Cost: 0.8736\n",
      "Validation Cost: 0.9931\n",
      "Training Cost: 0.8473\n",
      "Validation Cost: 0.9712\n",
      "Training Cost: 0.8240\n",
      "Validation Cost: 0.9525\n",
      "Training Cost: 0.8030\n",
      "Validation Cost: 0.9365\n",
      "Training Cost: 0.7840\n",
      "Validation Cost: 0.9226\n",
      "Training Cost: 0.7666\n",
      "Validation Cost: 0.9104\n"
     ]
    }
   ],
   "source": [
    "K = 50\n",
    "emb_user = create_embedings(num_users, K)\n",
    "emb_movie = create_embedings(num_movies, K)\n",
    "emb_user, emb_movie = gradient_descent(df_train, emb_user, emb_movie, iterations=2000, learning_rate=1, df_val=df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:49:27.652420Z",
     "start_time": "2018-06-01T09:48:24.374355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cost: 12.4318\n",
      "Validation Cost: 12.5388\n",
      "Training Cost: 7.2795\n",
      "Validation Cost: 7.4154\n",
      "Training Cost: 4.2089\n",
      "Validation Cost: 4.3336\n",
      "Training Cost: 3.0034\n",
      "Validation Cost: 3.1070\n",
      "Training Cost: 2.3839\n",
      "Validation Cost: 2.4764\n",
      "Training Cost: 2.0212\n",
      "Validation Cost: 2.1098\n",
      "Training Cost: 1.7884\n",
      "Validation Cost: 1.8766\n",
      "Training Cost: 1.6286\n",
      "Validation Cost: 1.7181\n",
      "Training Cost: 1.5131\n",
      "Validation Cost: 1.6050\n",
      "Training Cost: 1.4265\n",
      "Validation Cost: 1.5212\n",
      "Training Cost: 1.3594\n",
      "Validation Cost: 1.4574\n",
      "Training Cost: 1.3063\n",
      "Validation Cost: 1.4077\n",
      "Training Cost: 1.2632\n",
      "Validation Cost: 1.3682\n",
      "Training Cost: 1.2277\n",
      "Validation Cost: 1.3364\n",
      "Training Cost: 1.1978\n",
      "Validation Cost: 1.3104\n",
      "Training Cost: 1.1724\n",
      "Validation Cost: 1.2890\n",
      "Training Cost: 1.1503\n",
      "Validation Cost: 1.2711\n",
      "Training Cost: 1.1310\n",
      "Validation Cost: 1.2560\n",
      "Training Cost: 1.1138\n",
      "Validation Cost: 1.2433\n",
      "Training Cost: 1.0982\n",
      "Validation Cost: 1.2324\n"
     ]
    }
   ],
   "source": [
    "K = 50\n",
    "emb_user_reg = create_embedings(num_users, K)\n",
    "emb_movie_reg = create_embedings(num_movies, K)\n",
    "emb_user_reg, emb_movie_reg = gradient_descent_reg(df_train, emb_user_reg, emb_movie_reg, iterations=2000, learning_rate=1, df_val=df_val, reg_param=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:42:54.970573Z",
     "start_time": "2018-06-01T09:42:54.888751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7665730026459857 0.9104271876851561\n"
     ]
    }
   ],
   "source": [
    "train_mse = cost(df_train, emb_user, emb_movie)\n",
    "val_mse = cost(df_val, emb_user, emb_movie)\n",
    "print(train_mse, val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T09:50:57.117769Z",
     "start_time": "2018-06-01T09:50:57.036510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0841202174680702 1.2232326960254476\n"
     ]
    }
   ],
   "source": [
    "reg_param = 10\n",
    "num_estimates = (emb_user_reg.shape[0] + emb_movie_reg.shape[0]) * emb_user_reg.shape[1]\n",
    "rp = reg_param/num_estimates\n",
    "train_mse_reg = cost_reg(df_train, emb_user_reg, emb_movie_reg, rp)\n",
    "val_mse_reg = cost_reg(df_val, emb_user_reg, emb_movie_reg, rp)\n",
    "print(train_mse_reg, val_mse_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
